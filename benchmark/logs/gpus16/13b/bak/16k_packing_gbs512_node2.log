13b, 16k, gbs=512: dp=16, tp=1, pp=1, mbs=32
LOCAL_IP = 10.64.24.51
DP=16, MP=1, PP=1
[2024-02-09 09:55:56,071] torch.distributed.run: [WARNING] 
[2024-02-09 09:55:56,071] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 09:55:56,071] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 09:55:56,071] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 16, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 16
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 32
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 1
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.103 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.657 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 791692 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 791693 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 791688 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 791691 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 791694 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 791690 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 791687 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 791689 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[2024-02-09 09:56:21,733] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 228627) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_09:56:21
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 228628)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_09:56:21
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 228629)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_09:56:21
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 228630)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_09:56:21
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 228631)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_09:56:21
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 228632)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_09:56:21
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 228633)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_09:56:21
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 228634)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_09:56:21
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 228627)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=16, tp=1, pp=1, mbs=16
LOCAL_IP = 10.64.24.51
DP=16, MP=1, PP=1
[2024-02-09 09:59:44,450] torch.distributed.run: [WARNING] 
[2024-02-09 09:59:44,450] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 09:59:44,450] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 09:59:44,450] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 16, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 16
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 16
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 2
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.099 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.541 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 795964 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()Traceback (most recent call last):

  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
        _warmup_jit_function()_warmup_jit_function()

  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
        output = bias_gelu(bias, input)output = bias_gelu(bias, input)

RuntimeErrorRuntimeError: : The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 795968 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 795965 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 795966 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
    pretrain(train_dataset_provider,  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain

  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()    
output = bias_gelu(bias, input)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 795967 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 795962 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 795963 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 795961 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[2024-02-09 10:00:09,521] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 229090) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_10:00:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 229091)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_10:00:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 229092)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_10:00:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 229093)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_10:00:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 229094)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_10:00:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 229095)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_10:00:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 229096)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_10:00:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 229097)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_10:00:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 229090)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=16, tp=1, pp=1, mbs=8
LOCAL_IP = 10.64.24.51
DP=16, MP=1, PP=1
[2024-02-09 10:03:32,280] torch.distributed.run: [WARNING] 
[2024-02-09 10:03:32,280] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 10:03:32,280] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 10:03:32,280] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 16, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 16
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 8
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 4
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.093 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.705 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 800231 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 800238 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
Traceback (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 800237 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>

    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
    output = bias_gelu(bias, input)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 800235 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 800233 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 800234 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 800236 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 800232 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


[2024-02-09 10:03:58,289] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 229553) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_10:03:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 229554)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_10:03:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 229555)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_10:03:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 229556)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_10:03:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 229557)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_10:03:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 229558)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_10:03:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 229559)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_10:03:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 229560)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_10:03:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 229553)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=16, tp=1, pp=1, mbs=4
LOCAL_IP = 10.64.24.51
DP=16, MP=1, PP=1
[2024-02-09 10:07:21,029] torch.distributed.run: [WARNING] 
[2024-02-09 10:07:21,029] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 10:07:21,029] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 10:07:21,029] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 16, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 16
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 8
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.102 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.486 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 12.074
[after megatron is initialized] datetime: 2024-02-09 10:07:44 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 12927027200
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.11 GiB is free. Process 804074 has 76.98 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 123.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 5 has a total capacty of 79.11 GiB of which 2.00 GiB is free. Process 804079 has 77.10 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 242.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 1 has a total capacty of 79.11 GiB of which 1.95 GiB is free. Process 804075 has 77.15 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 292.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 2 has a total capacty of 79.11 GiB of which 2.16 GiB is free. Process 804076 has 76.94 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 79.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 6 has a total capacty of 79.11 GiB of which 2.02 GiB is free. Process 804080 has 77.08 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 223.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 4 has a total capacty of 79.11 GiB of which 2.00 GiB is free. Process 804078 has 77.10 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 242.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 3 has a total capacty of 79.11 GiB of which 2.17 GiB is free. Process 804077 has 76.93 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 67.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 7 has a total capacty of 79.11 GiB of which 2.14 GiB is free. Process 804081 has 76.96 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 93.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-02-09 10:07:47,055] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 230017 closing signal SIGTERM
[2024-02-09 10:07:47,056] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 230023 closing signal SIGTERM
[2024-02-09 10:07:47,485] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 230016) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_10:07:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 230018)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_10:07:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 230019)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_10:07:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 230020)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_10:07:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 230021)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_10:07:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 230022)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_10:07:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 230016)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=16, tp=1, pp=1, mbs=2
LOCAL_IP = 10.64.24.51
DP=16, MP=1, PP=1
[2024-02-09 10:10:50,188] torch.distributed.run: [WARNING] 
[2024-02-09 10:10:50,188] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 10:10:50,188] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 10:10:50,188] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 16, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 16
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 2
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 16
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.090 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.661 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 12.035
[after megatron is initialized] datetime: 2024-02-09 10:11:12 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 12927027200
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 4 has a total capacty of 79.11 GiB of which 2.00 GiB is free. Process 807870 has 77.10 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 242.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.11 GiB is free. Process 807866 has 76.98 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 123.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 3 has a total capacty of 79.11 GiB of which 2.17 GiB is free. Process 807869 has 76.93 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 67.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
Traceback (most recent call last):
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>

  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
Traceback (most recent call last):
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 2 has a total capacty of 79.11 GiB of which 2.16 GiB is free. Process 807868 has 76.94 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 79.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 1 has a total capacty of 79.11 GiB of which 1.95 GiB is free. Process 807867 has 77.15 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 292.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 7 has a total capacty of 79.11 GiB of which 2.14 GiB is free. Process 807873 has 76.96 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 93.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 5 has a total capacty of 79.11 GiB of which 2.00 GiB is free. Process 807871 has 77.10 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 242.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 6 has a total capacty of 79.11 GiB of which 2.02 GiB is free. Process 807872 has 77.08 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 223.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-02-09 10:11:15,252] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 230479) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_10:11:15
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 230480)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_10:11:15
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 230481)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_10:11:15
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 230482)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_10:11:15
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 230483)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_10:11:15
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 230484)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_10:11:15
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 230485)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_10:11:15
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 230486)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_10:11:15
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 230479)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=16, tp=1, pp=1, mbs=1
LOCAL_IP = 10.64.24.51
DP=16, MP=1, PP=1
[2024-02-09 10:14:37,966] torch.distributed.run: [WARNING] 
[2024-02-09 10:14:37,966] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 10:14:37,966] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 10:14:37,966] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 16, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 16
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 1
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 32
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.116 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.561 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 12.402
[after megatron is initialized] datetime: 2024-02-09 10:14:59 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 12927027200
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 5 has a total capacty of 79.11 GiB of which 2.00 GiB is free. Process 812153 has 77.10 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 242.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 1 has a total capacty of 79.11 GiB of which 1.95 GiB is free. Process 812149 has 77.15 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 292.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.11 GiB is free. Process 812148 has 76.98 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 123.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 4 has a total capacty of 79.11 GiB of which 2.00 GiB is free. Process 812152 has 77.10 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 242.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
        optimizer = get_megatron_optimizer(model, no_wd_decay_cond,pretrain(train_dataset_provider,

  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 3 has a total capacty of 79.11 GiB of which 2.17 GiB is free. Process 812151 has 76.93 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 67.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 7 has a total capacty of 79.11 GiB of which 2.14 GiB is free. Process 812155 has 76.96 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 93.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 6 has a total capacty of 79.11 GiB of which 2.02 GiB is free. Process 812154 has 77.08 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 223.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 113, in pretrain
    model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 370, in setup_model_and_optimizer
    optimizer = get_megatron_optimizer(model, no_wd_decay_cond,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/__init__.py", line 128, in get_megatron_optimizer
    return opt_ty(optimizer,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py", line 417, in __init__
    param_buffer = torch.tensor(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.16 GiB. GPU 2 has a total capacty of 79.11 GiB of which 2.16 GiB is free. Process 812150 has 76.94 GiB memory in use. Of the allocated memory 75.25 GiB is allocated by PyTorch, and 79.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-02-09 10:15:03,053] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 230942) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_10:15:03
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 230943)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_10:15:03
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 230944)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_10:15:03
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 230945)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_10:15:03
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 230946)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_10:15:03
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 230947)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_10:15:03
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 230948)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_10:15:03
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 230949)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_10:15:03
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 230942)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=8, tp=2, pp=1, mbs=32
LOCAL_IP = 10.64.24.51
DP=8, MP=2, PP=1
[2024-02-09 10:18:25,826] torch.distributed.run: [WARNING] 
[2024-02-09 10:18:25,826] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 10:18:25,826] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 10:18:25,826] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 32
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 2
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.102 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.630 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 816427 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 816429 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 816428 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 816424 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 816423 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 816425 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 816430 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 816426 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[2024-02-09 10:18:51,853] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 231405) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_10:18:51
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 231406)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_10:18:51
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 231407)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_10:18:51
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 231408)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_10:18:51
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 231409)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_10:18:51
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 231410)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_10:18:51
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 231411)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_10:18:51
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 231412)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_10:18:51
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 231405)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=8, tp=2, pp=1, mbs=16
LOCAL_IP = 10.64.24.51
DP=8, MP=2, PP=1
[2024-02-09 10:22:14,636] torch.distributed.run: [WARNING] 
[2024-02-09 10:22:14,636] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 10:22:14,636] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 10:22:14,636] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 16
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 4
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.102 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.483 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 819974 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 819977 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 819973 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 819976 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,    
pretrain(train_dataset_provider,  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain

  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 819980 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 819978 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 819979 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 819975 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


[2024-02-09 10:22:39,741] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 231868) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_10:22:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 231869)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_10:22:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 231870)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_10:22:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 231871)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_10:22:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 231872)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_10:22:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 231873)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_10:22:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 231874)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_10:22:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 231875)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_10:22:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 231868)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=8, tp=2, pp=1, mbs=8
LOCAL_IP = 10.64.24.51
DP=8, MP=2, PP=1
[2024-02-09 10:26:02,496] torch.distributed.run: [WARNING] 
[2024-02-09 10:26:02,496] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 10:26:02,496] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 10:26:02,496] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 8
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 8
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.104 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.473 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 12.009
[after megatron is initialized] datetime: 2024-02-09 10:26:25 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 6506403840
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 6506403840
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
> learning rate decay style: cosine
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-02-09 10:26:26 
> building GPT2BPETokenizer tokenizer ...
> building GPT2BPETokenizer tokenizer ...
> building GPT2BPETokenizer tokenizer ...
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...

 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
Loading exists cache end, time cost:  5.471 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Loading exists cache end, time cost:  5.489 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Loading exists cache end, time cost:  5.689 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Loading exists cache end, time cost:  8.042 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Cutting or padding data end, time cost:  18.878 s
consumed_train_samples = 0, dataloader_type = single
Cutting or padding data end, time cost:  18.762 s
consumed_train_samples = 0, dataloader_type = single
Cutting or padding data end, time cost:  18.980 s
consumed_train_samples = 0, dataloader_type = single
Cutting or padding data end, time cost:  18.459 s
consumed_train_samples = 0, dataloader_type = single
[after dataloaders are built] datetime: 2024-02-09 10:26:53 
done with setup ...
training ...
[before the start of training step] datetime: 2024-02-09 10:26:53 
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 165, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 165, in pretrain
    iteration = train(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 699, in train
    iteration = train(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 699, in train
    train_step(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 416, in train_step
    train_step(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 416, in train_step
    losses_reduced = forward_backward_func(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 372, in forward_backward_no_pipelining
    losses_reduced = forward_backward_func(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 372, in forward_backward_no_pipelining
    output_tensor = forward_step(forward_step_func, data_iterator,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 228, in forward_step
    output_tensor = forward_step(forward_step_func, data_iterator,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 228, in forward_step
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 153, in forward_step
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 153, in forward_step
    output_tensor = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    output_tensor = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/distributed.py", line 58, in forward
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/distributed.py", line 58, in forward
    return self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/module.py", line 183, in forward
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/module.py", line 183, in forward
    outputs = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    outputs = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 134, in forward
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 134, in forward
    return post_language_model_processing(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 43, in post_language_model_processing
    return post_language_model_processing(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 43, in post_language_model_processing
    loss = tensor_parallel.vocab_parallel_cross_entropy(output.float(), labels)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 143, in vocab_parallel_cross_entropy
    loss = tensor_parallel.vocab_parallel_cross_entropy(output.float(), labels)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 143, in vocab_parallel_cross_entropy
    return _VocabParallelCrossEntropy.apply(vocab_parallel_logits, target, label_smoothing)
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 25, in forward
    return _VocabParallelCrossEntropy.apply(vocab_parallel_logits, target, label_smoothing)
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 25, in forward
    vocab_parallel_logits = vocab_parallel_logits - logits_max.unsqueeze(dim=-1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.31 GiB. GPU 2 has a total capacty of 79.11 GiB of which 495.50 MiB is free. Process 824128 has 78.61 GiB memory in use. Of the allocated memory 69.05 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    vocab_parallel_logits = vocab_parallel_logits - logits_max.unsqueeze(dim=-1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.31 GiB. GPU 3 has a total capacty of 79.11 GiB of which 495.50 MiB is free. Process 824129 has 78.61 GiB memory in use. Of the allocated memory 69.05 GiB is allocated by PyTorch, and 7.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 165, in pretrain
    iteration = train(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 699, in train
    train_step(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 416, in train_step
    losses_reduced = forward_backward_func(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 372, in forward_backward_no_pipelining
    output_tensor = forward_step(forward_step_func, data_iterator,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 228, in forward_step
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 153, in forward_step
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,    
pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 165, in pretrain
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 165, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output_tensor = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/distributed.py", line 58, in forward
    iteration = train(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 699, in train
    iteration = train(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 699, in train
    train_step(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 416, in train_step
    train_step(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 416, in train_step
    losses_reduced = forward_backward_func(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 372, in forward_backward_no_pipelining
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 165, in pretrain
    losses_reduced = forward_backward_func(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 372, in forward_backward_no_pipelining
    return self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/module.py", line 183, in forward
    iteration = train(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 699, in train
    output_tensor = forward_step(forward_step_func, data_iterator,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 228, in forward_step
    output_tensor = forward_step(forward_step_func, data_iterator,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 228, in forward_step
    outputs = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    train_step(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 416, in train_step
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 153, in forward_step
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 134, in forward
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 153, in forward_step
    losses_reduced = forward_backward_func(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 372, in forward_backward_no_pipelining
    output_tensor = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return post_language_model_processing(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 43, in post_language_model_processing
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    output_tensor = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/distributed.py", line 58, in forward
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    output_tensor = forward_step(forward_step_func, data_iterator,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 228, in forward_step
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/distributed.py", line 58, in forward
    loss = tensor_parallel.vocab_parallel_cross_entropy(output.float(), labels)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.31 GiB. GPU 5 has a total capacty of 79.11 GiB of which 6.62 GiB is free. Process 824131 has 72.47 GiB memory in use. Of the allocated memory 63.15 GiB is allocated by PyTorch, and 6.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    return self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 153, in forward_step
    return self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/module.py", line 183, in forward
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/module.py", line 183, in forward
    output_tensor = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    outputs = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/distributed.py", line 58, in forward
    outputs = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 134, in forward
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 134, in forward
    return self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
        return forward_call(*args, **kwargs)return post_language_model_processing(

  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/module.py", line 183, in forward
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 43, in post_language_model_processing
    return post_language_model_processing(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 43, in post_language_model_processing
    loss = tensor_parallel.vocab_parallel_cross_entropy(output.float(), labels)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.31 GiB. GPU 1 has a total capacty of 79.11 GiB of which 6.66 GiB is free. Process 824127 has 72.44 GiB memory in use. Of the allocated memory 65.49 GiB is allocated by PyTorch, and 4.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    outputs = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    loss = tensor_parallel.vocab_parallel_cross_entropy(output.float(), labels)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.31 GiB. GPU 0 has a total capacty of 79.11 GiB of which 6.66 GiB is free. Process 824126 has 72.44 GiB memory in use. Of the allocated memory 65.49 GiB is allocated by PyTorch, and 4.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 134, in forward
    return post_language_model_processing(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 43, in post_language_model_processing
    loss = tensor_parallel.vocab_parallel_cross_entropy(output.float(), labels)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.31 GiB. GPU 4 has a total capacty of 79.11 GiB of which 6.62 GiB is free. Process 824130 has 72.47 GiB memory in use. Of the allocated memory 63.15 GiB is allocated by PyTorch, and 6.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 165, in pretrain
    iteration = train(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 699, in train
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    train_step(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 416, in train_step
    losses_reduced = forward_backward_func(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 372, in forward_backward_no_pipelining
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 165, in pretrain
    output_tensor = forward_step(forward_step_func, data_iterator,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 228, in forward_step
    iteration = train(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 699, in train
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 153, in forward_step
    train_step(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 416, in train_step
    output_tensor = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/distributed.py", line 58, in forward
    losses_reduced = forward_backward_func(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 372, in forward_backward_no_pipelining
    return self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    output_tensor = forward_step(forward_step_func, data_iterator,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 228, in forward_step
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/module.py", line 183, in forward
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 153, in forward_step
    outputs = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 134, in forward
    output_tensor = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return post_language_model_processing(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 43, in post_language_model_processing
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/distributed.py", line 58, in forward
    loss = tensor_parallel.vocab_parallel_cross_entropy(output.float(), labels)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 143, in vocab_parallel_cross_entropy
    return self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/module.py", line 183, in forward
    return _VocabParallelCrossEntropy.apply(vocab_parallel_logits, target, label_smoothing)
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 25, in forward
    outputs = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    vocab_parallel_logits = vocab_parallel_logits - logits_max.unsqueeze(dim=-1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.31 GiB. GPU 7 has a total capacty of 79.11 GiB of which 505.50 MiB is free. Process 824133 has 78.60 GiB memory in use. Of the allocated memory 66.22 GiB is allocated by PyTorch, and 9.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 134, in forward
    return post_language_model_processing(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 43, in post_language_model_processing
    loss = tensor_parallel.vocab_parallel_cross_entropy(output.float(), labels)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 143, in vocab_parallel_cross_entropy
    return _VocabParallelCrossEntropy.apply(vocab_parallel_logits, target, label_smoothing)
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 25, in forward
    vocab_parallel_logits = vocab_parallel_logits - logits_max.unsqueeze(dim=-1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.31 GiB. GPU 6 has a total capacty of 79.11 GiB of which 505.50 MiB is free. Process 824132 has 78.60 GiB memory in use. Of the allocated memory 66.22 GiB is allocated by PyTorch, and 9.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-02-09 10:26:58,531] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 232331 closing signal SIGTERM
[2024-02-09 10:26:58,531] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 232333 closing signal SIGTERM
[2024-02-09 10:26:58,532] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 232335 closing signal SIGTERM
[2024-02-09 10:26:58,533] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 232337 closing signal SIGTERM
[2024-02-09 10:27:00,513] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 1 (pid: 232332) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_10:26:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 232334)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_10:26:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 232336)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_10:26:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 232338)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_10:26:58
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 232332)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=8, tp=2, pp=1, mbs=4
LOCAL_IP = 10.64.24.51
DP=8, MP=2, PP=1
[2024-02-09 10:29:43,180] torch.distributed.run: [WARNING] 
[2024-02-09 10:29:43,180] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 10:29:43,180] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 10:29:43,180] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 16
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.105 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.647 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 12.401
[after megatron is initialized] datetime: 2024-02-09 10:30:06 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 6506403840
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 6506403840
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
> learning rate decay style: cosine
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-02-09 10:30:07 
> building GPT2BPETokenizer tokenizer ...
> building GPT2BPETokenizer tokenizer ...
> building GPT2BPETokenizer tokenizer ...
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304) > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)

Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...

 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
Loading exists cache end, time cost:  5.320 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Loading exists cache end, time cost:  5.382 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Loading exists cache end, time cost:  5.392 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Loading exists cache end, time cost:  5.610 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Cutting or padding data end, time cost:  18.572 s
consumed_train_samples = 0, dataloader_type = single
Cutting or padding data end, time cost:  18.662 s
consumed_train_samples = 0, dataloader_type = single
Cutting or padding data end, time cost:  18.867 s
consumed_train_samples = 0, dataloader_type = single
Cutting or padding data end, time cost:  18.786 s
consumed_train_samples = 0, dataloader_type = single
[after dataloaders are built] datetime: 2024-02-09 10:30:32 
done with setup ...
training ...
[before the start of training step] datetime: 2024-02-09 10:30:32 
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 165, in pretrain
    iteration = train(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 699, in train
    train_step(forward_step_func,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 416, in train_step
    losses_reduced = forward_backward_func(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 372, in forward_backward_no_pipelining
    output_tensor = forward_step(forward_step_func, data_iterator,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/pipeline_parallel/schedules.py", line 228, in forward_step
    output_tensor, loss_func = forward_step_func(data_iterator, model)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 153, in forward_step
    output_tensor = model(tokens, position_ids, attention_mask,
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/distributed.py", line 58, in forward
    return self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/module.py", line 183, in forward
    outputs = self.module(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 134, in forward
    return post_language_model_processing(
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/gpt_model.py", line 43, in post_language_model_processing
    loss = tensor_parallel.vocab_parallel_cross_entropy(output.float(), labels)
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 143, in vocab_parallel_cross_entropy
    return _VocabParallelCrossEntropy.apply(vocab_parallel_logits, target, label_smoothing)
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/tensor_parallel/cross_entropy.py", line 25, in forward
    vocab_parallel_logits = vocab_parallel_logits - logits_max.unsqueeze(dim=-1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.16 GiB. GPU 0 has a total capacty of 79.11 GiB of which 5.88 GiB is free. Process 829227 has 73.22 GiB memory in use. Of the allocated memory 57.20 GiB is allocated by PyTorch, and 12.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2024-02-09 10:31:04,236] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 233603 closing signal SIGTERM
[2024-02-09 10:31:04,236] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 233604 closing signal SIGTERM
[2024-02-09 10:31:04,237] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 233605 closing signal SIGTERM
[2024-02-09 10:31:04,237] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 233606 closing signal SIGTERM
[2024-02-09 10:31:04,238] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 233607 closing signal SIGTERM
[2024-02-09 10:31:04,238] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 233608 closing signal SIGTERM
[2024-02-09 10:31:04,239] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 233609 closing signal SIGTERM
[2024-02-09 10:31:04,954] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 233602) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_10:31:04
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 233602)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=8, tp=2, pp=1, mbs=2
LOCAL_IP = 10.64.24.51
DP=8, MP=2, PP=1
[2024-02-09 10:33:17,580] torch.distributed.run: [WARNING] 
[2024-02-09 10:33:17,580] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 10:33:17,580] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 10:33:17,580] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 2
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 32
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.096 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.488 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 11.988
[after megatron is initialized] datetime: 2024-02-09 10:33:39 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 6506403840
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 6506403840
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
> learning rate decay style: cosine
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-02-09 10:33:40 
> building GPT2BPETokenizer tokenizer ...
> building GPT2BPETokenizer tokenizer ...
> building GPT2BPETokenizer tokenizer ...> building GPT2BPETokenizer tokenizer ...

 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
Loading exists cache end, time cost:  5.265 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Loading exists cache end, time cost:  5.306 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Loading exists cache end, time cost:  5.507 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Loading exists cache end, time cost:  5.576 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
Cutting or padding data end, time cost:  18.657 s
consumed_train_samples = 0, dataloader_type = single
Cutting or padding data end, time cost:  18.618 s
consumed_train_samples = 0, dataloader_type = single
Cutting or padding data end, time cost:  18.749 s
consumed_train_samples = 0, dataloader_type = single
Cutting or padding data end, time cost:  18.703 s
consumed_train_samples = 0, dataloader_type = single
[after dataloaders are built] datetime: 2024-02-09 10:34:05 
done with setup ...
training ...
[before the start of training step] datetime: 2024-02-09 10:34:05 
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
[E ProcessGroupNCCL.cpp:467] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800021 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800103 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800294 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800265 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800395 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800551 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800987 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800984 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800021 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800021 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800103 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800103 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800294 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800294 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800395 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800395 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800551 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800551 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800265 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800265 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800987 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800987 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800984 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=1800000) ran for 1800984 milliseconds before timing out.
[2024-02-09 11:04:49,791] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 234968 closing signal SIGTERM
[2024-02-09 11:05:19,791] torch.distributed.elastic.multiprocessing.api: [WARNING] Unable to shutdown process 234968 via Signals.SIGTERM, forcefully exiting via Signals.SIGKILL
[2024-02-09 11:05:20,417] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 0 (pid: 234963) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
pretrain_gpt.py FAILED
-------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_11:04:49
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : -6 (pid: 234964)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 234964
[2]:
  time      : 2024-02-09_11:04:49
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : -6 (pid: 234965)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 234965
[3]:
  time      : 2024-02-09_11:04:49
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : -6 (pid: 234966)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 234966
[4]:
  time      : 2024-02-09_11:04:49
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : -6 (pid: 234967)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 234967
[5]:
  time      : 2024-02-09_11:04:49
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : -6 (pid: 234969)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 234969
[6]:
  time      : 2024-02-09_11:04:49
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : -6 (pid: 234970)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 234970
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_11:04:49
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : -6 (pid: 234963)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 234963
=======================================================
13b, 16k, gbs=512: dp=8, tp=2, pp=1, mbs=1
LOCAL_IP = 10.64.24.51
DP=8, MP=2, PP=1
[2024-02-09 11:08:33,131] torch.distributed.run: [WARNING] 
[2024-02-09 11:08:33,131] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 11:08:33,131] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 11:08:33,131] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 2, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 1
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 64
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: [enforce fail at /opt/pytorch/pytorch/third_party/gloo/gloo/transport/tcp/address.cc:45] sizeof(impl_) == bytes.size(). 136 vs 58
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: [enforce fail at /opt/pytorch/pytorch/third_party/gloo/gloo/transport/tcp/address.cc:45] sizeof(impl_) == bytes.size(). 136 vs 58
[2024-02-09 11:08:48,807] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 236325 closing signal SIGTERM
[2024-02-09 11:08:48,807] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 236327 closing signal SIGTERM
[2024-02-09 11:08:48,808] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 236328 closing signal SIGTERM
[2024-02-09 11:08:48,808] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 236329 closing signal SIGTERM
[2024-02-09 11:08:48,808] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 236330 closing signal SIGTERM
[2024-02-09 11:08:48,809] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 236331 closing signal SIGTERM
[2024-02-09 11:08:49,487] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 236324) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_11:08:48
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 236326)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_11:08:48
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 236324)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=8, tp=1, pp=2, mbs=32
LOCAL_IP = 10.64.24.51
DP=8, MP=1, PP=2
[2024-02-09 11:11:12,114] torch.distributed.run: [WARNING] 
[2024-02-09 11:11:12,114] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 11:11:12,114] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 11:11:12,114] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 32
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 2
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.123 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 165.387 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 872178 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 872177 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 872173 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
    output = bias_gelu(bias, input)  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>

RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 872176 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 872174 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 872172 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 872175 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 872171 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[2024-02-09 11:14:28,163] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 236560) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_11:14:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 236561)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_11:14:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 236562)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_11:14:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 236563)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_11:14:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 236564)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_11:14:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 236565)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_11:14:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 236566)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_11:14:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 236567)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_11:14:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 236560)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=8, tp=1, pp=2, mbs=16
LOCAL_IP = 10.64.24.51
DP=8, MP=1, PP=2
[2024-02-09 11:17:50,930] torch.distributed.run: [WARNING] 
[2024-02-09 11:17:50,930] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 11:17:50,930] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 11:17:50,930] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 16
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 4
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.122 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.475 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 878416 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 878409 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 878412 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 878414 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 878415 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 878410 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 878413 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 878411 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[2024-02-09 11:18:19,108] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 237023) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_11:18:19
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 237024)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_11:18:19
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 237025)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_11:18:19
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 237026)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_11:18:19
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 237027)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_11:18:19
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 237028)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_11:18:19
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 237029)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_11:18:19
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 237030)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_11:18:19
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 237023)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=8, tp=1, pp=2, mbs=8
LOCAL_IP = 10.64.24.51
DP=8, MP=1, PP=2
[2024-02-09 11:21:41,869] torch.distributed.run: [WARNING] 
[2024-02-09 11:21:41,869] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 11:21:41,869] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 11:21:41,869] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 8
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 8
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.084 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.686 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 882692 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 882688 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 882687 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 882690 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 882694 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 882691 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 882693 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 882689 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


[2024-02-09 11:22:06,912] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 237486) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_11:22:06
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 237487)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_11:22:06
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 237488)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_11:22:06
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 237489)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_11:22:06
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 237490)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_11:22:06
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 237491)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_11:22:06
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 237492)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_11:22:06
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 237493)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_11:22:06
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 237486)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=8, tp=1, pp=2, mbs=4
LOCAL_IP = 10.64.24.51
DP=8, MP=1, PP=2
[2024-02-09 11:25:29,660] torch.distributed.run: [WARNING] 
[2024-02-09 11:25:29,660] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 11:25:29,660] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 11:25:29,660] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 16
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.095 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.622 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 12.458
[after megatron is initialized] datetime: 2024-02-09 11:25:52 
building GPT model ...
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 6634229760
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
> learning rate decay style: cosine
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
[E ProcessGroupNCCL.cpp:467] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600390 milliseconds before timing out.
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-02-09 11:35:53 
[E ProcessGroupNCCL.cpp:467] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600467 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600502 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600610 milliseconds before timing out.
> building GPT2BPETokenizer tokenizer ...
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600502 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600502 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:852] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600390 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600390 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600467 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600467 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600610 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600610 milliseconds before timing out.
[2024-02-09 11:36:00,250] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 237949 closing signal SIGTERM
[2024-02-09 11:36:00,250] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 237950 closing signal SIGTERM
[2024-02-09 11:36:00,250] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 237951 closing signal SIGTERM
[2024-02-09 11:36:00,251] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 237953 closing signal SIGTERM
[2024-02-09 11:36:00,251] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 237954 closing signal SIGTERM
[2024-02-09 11:36:00,251] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 237955 closing signal SIGTERM
[2024-02-09 11:36:00,252] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 237956 closing signal SIGTERM
[2024-02-09 11:36:08,828] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 3 (pid: 237952) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
pretrain_gpt.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_11:36:00
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : -6 (pid: 237952)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 237952
=======================================================
13b, 16k, gbs=512: dp=8, tp=1, pp=2, mbs=2
LOCAL_IP = 10.64.24.51
DP=8, MP=1, PP=2
[2024-02-09 11:38:21,446] torch.distributed.run: [WARNING] 
[2024-02-09 11:38:21,446] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 11:38:21,446] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 11:38:21,446] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 2
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 32
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.109 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.440 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 12.182
[after megatron is initialized] datetime: 2024-02-09 11:40:05 
building GPT model ...
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 6634229760
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
> learning rate decay style: cosine
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
[E ProcessGroupNCCL.cpp:467] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600726 milliseconds before timing out.
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-02-09 11:50:07 
[E ProcessGroupNCCL.cpp:467] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600876 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600883 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600953 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600726 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600726 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600876 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600876 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600953 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600953 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600883 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600883 milliseconds before timing out.
[2024-02-09 11:50:14,150] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238437 closing signal SIGTERM
[2024-02-09 11:50:14,150] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238438 closing signal SIGTERM
[2024-02-09 11:50:14,150] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238439 closing signal SIGTERM
[2024-02-09 11:50:14,150] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238440 closing signal SIGTERM
[2024-02-09 11:50:14,151] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238441 closing signal SIGTERM
[2024-02-09 11:50:14,151] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238442 closing signal SIGTERM
[2024-02-09 11:50:14,152] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238443 closing signal SIGTERM
[2024-02-09 11:50:17,521] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 0 (pid: 238436) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
pretrain_gpt.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_11:50:14
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : -6 (pid: 238436)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 238436
=======================================================
13b, 16k, gbs=512: dp=8, tp=1, pp=2, mbs=1
LOCAL_IP = 10.64.24.51
DP=8, MP=1, PP=2
[2024-02-09 11:52:30,152] torch.distributed.run: [WARNING] 
[2024-02-09 11:52:30,152] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 11:52:30,152] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 11:52:30,152] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 8
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 1
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 64
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.099 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.503 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 11.704
[after megatron is initialized] datetime: 2024-02-09 11:53:06 
building GPT model ...
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 6634229760
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
> learning rate decay style: cosine
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
[E ProcessGroupNCCL.cpp:467] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600686 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600798 milliseconds before timing out.
[after model, optimizer, and learning rate scheduler are built] datetime: 2024-02-09 12:03:08 
[E ProcessGroupNCCL.cpp:467] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600856 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600960 milliseconds before timing out.
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600856 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600856 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600960 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600960 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600798 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600798 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600686 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600686 milliseconds before timing out.
[2024-02-09 12:03:15,334] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238923 closing signal SIGTERM
[2024-02-09 12:03:15,334] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238924 closing signal SIGTERM
[2024-02-09 12:03:15,334] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238925 closing signal SIGTERM
[2024-02-09 12:03:15,334] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238927 closing signal SIGTERM
[2024-02-09 12:03:15,335] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238928 closing signal SIGTERM
[2024-02-09 12:03:15,335] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238929 closing signal SIGTERM
[2024-02-09 12:03:15,336] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 238930 closing signal SIGTERM
[2024-02-09 12:03:21,408] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 3 (pid: 238926) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
pretrain_gpt.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_12:03:15
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : -6 (pid: 238926)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 238926
=======================================================
13b, 16k, gbs=512: dp=4, tp=4, pp=1, mbs=32
LOCAL_IP = 10.64.24.51
DP=4, MP=4, PP=1
[2024-02-09 12:05:34,058] torch.distributed.run: [WARNING] 
[2024-02-09 12:05:34,058] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 12:05:34,058] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 12:05:34,058] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 4, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 32
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 4
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 4
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 431 dummy tokens (new size: 50688)
> initializing torch distributed ...
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 82, in initialize_megatron
    _compile_dependencies()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 133, in _compile_dependencies
    torch.distributed.barrier()
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3685, in barrier
    work = default_pg.barrier(opts=opts)
RuntimeError: [6] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: Socket Timeout
Exception raised from doWait at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/TCPStore.cpp:445 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f7a7e9b0449 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x6a (0x7f7a7e96b1d8 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x28c (0x7f7a3139123c in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2a (0x7f7a3139150a in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x76 (0x7f7a31391816 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2f (0x7f7a3134a2bf in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2f (0x7f7a3134a2bf in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2f (0x7f7a3134a2bf in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::PrefixStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2f (0x7f7a3134a2bf in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #9: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int) + 0x1fa (0x7f79e46d73da in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #10: c10d::ProcessGroupNCCL::getNCCLComm(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, int, bool) + 0x228 (0x7f79e46da908 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #11: <unknown function> + 0xe27d37 (0x7f79e46e6d37 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 (0x7f79e46e82e1 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x421 (0x7f79e46ea121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #14: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x8e4 (0x7f79e46f9994 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #15: <unknown function> + 0x4935c6f (0x7f7a31337c6f in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x494575c (0x7f7a3134775c in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x4952b12 (0x7f7a31354b12 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #18: <unknown function> + 0x49535b9 (0x7f7a313555b9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xb868a2 (0x7f7a37b1c8a2 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #20: <unknown function> + 0x39c407 (0x7f7a37332407 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #21: <unknown function> + 0x15fe0e (0x55c430fa4e0e in /usr/bin/python)
frame #22: _PyObject_MakeTpCall + 0x25b (0x55c430f9b5eb in /usr/bin/python)
frame #23: <unknown function> + 0x16e7bb (0x55c430fb37bb in /usr/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x1981 (0x55c430f8f0d1 in /usr/bin/python)
frame #25: _PyFunction_Vectorcall + 0x7c (0x55c430fa570c in /usr/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2b71 (0x55c430f902c1 in /usr/bin/python)
frame #27: _PyFunction_Vectorcall + 0x7c (0x55c430fa570c in /usr/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x6152 (0x55c430f938a2 in /usr/bin/python)
frame #29: _PyFunction_Vectorcall + 0x7c (0x55c430fa570c in /usr/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x6bd (0x55c430f8de0d in /usr/bin/python)
frame #31: _PyFunction_Vectorcall + 0x7c (0x55c430fa570c in /usr/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x1981 (0x55c430f8f0d1 in /usr/bin/python)
frame #33: _PyFunction_Vectorcall + 0x7c (0x55c430fa570c in /usr/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x1981 (0x55c430f8f0d1 in /usr/bin/python)
frame #35: <unknown function> + 0x239e56 (0x55c43107ee56 in /usr/bin/python)
frame #36: PyEval_EvalCode + 0x86 (0x55c43107ecf6 in /usr/bin/python)
frame #37: <unknown function> + 0x2647d8 (0x55c4310a97d8 in /usr/bin/python)
frame #38: <unknown function> + 0x25e0bb (0x55c4310a30bb in /usr/bin/python)
frame #39: <unknown function> + 0x264525 (0x55c4310a9525 in /usr/bin/python)
frame #40: _PyRun_SimpleFileObject + 0x1a8 (0x55c4310a8a08 in /usr/bin/python)
frame #41: _PyRun_AnyFileObject + 0x43 (0x55c4310a8653 in /usr/bin/python)
frame #42: Py_RunMain + 0x2be (0x55c43109b41e in /usr/bin/python)
frame #43: Py_BytesMain + 0x2d (0x55c431071cad in /usr/bin/python)
frame #44: <unknown function> + 0x29d90 (0x7f7a7ff05d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #45: __libc_start_main + 0x80 (0x7f7a7ff05e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #46: _start + 0x25 (0x55c431071ba5 in /usr/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up issue.
[2024-02-09 12:15:50,122] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239410 closing signal SIGTERM
[2024-02-09 12:15:50,122] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239411 closing signal SIGTERM
[2024-02-09 12:15:50,123] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239412 closing signal SIGTERM
[2024-02-09 12:15:50,124] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239413 closing signal SIGTERM
[2024-02-09 12:15:50,124] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239414 closing signal SIGTERM
[2024-02-09 12:15:50,125] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239415 closing signal SIGTERM
[2024-02-09 12:15:50,126] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239417 closing signal SIGTERM
[2024-02-09 12:15:50,804] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 6 (pid: 239416) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_12:15:50
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 239416)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=4, pp=1, mbs=16
LOCAL_IP = 10.64.24.51
DP=4, MP=4, PP=1
[2024-02-09 12:18:03,428] torch.distributed.run: [WARNING] 
[2024-02-09 12:18:03,428] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 12:18:03,428] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 12:18:03,428] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 4, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 16
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 4
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 8
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 431 dummy tokens (new size: 50688)
> initializing torch distributed ...
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 82, in initialize_megatron
    _compile_dependencies()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 133, in _compile_dependencies
    torch.distributed.barrier()
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3685, in barrier
    work = default_pg.barrier(opts=opts)
RuntimeError: [6] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: Socket Timeout
Exception raised from doWait at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/TCPStore.cpp:445 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fc8fd7b0449 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x6a (0x7fc8fd76b1d8 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #2: c10d::TCPStore::doWait(c10::ArrayRef<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::chrono::duration<long, std::ratio<1l, 1000l> >) + 0x28c (0x7fc8c4d9123c in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #3: c10d::TCPStore::doGet(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2a (0x7fc8c4d9150a in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #4: c10d::TCPStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x76 (0x7fc8c4d91816 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #5: c10d::PrefixStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2f (0x7fc8c4d4a2bf in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #6: c10d::PrefixStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2f (0x7fc8c4d4a2bf in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #7: c10d::PrefixStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2f (0x7fc8c4d4a2bf in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #8: c10d::PrefixStore::get(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x2f (0x7fc8c4d4a2bf in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #9: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int) + 0x1fa (0x7fc8780d73da in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #10: c10d::ProcessGroupNCCL::getNCCLComm(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<c10::Device, std::allocator<c10::Device> > const&, c10d::OpType, int, bool) + 0x228 (0x7fc8780da908 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #11: <unknown function> + 0xe27d37 (0x7fc8780e6d37 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #12: c10d::ProcessGroupNCCL::allreduce_impl(std::vector<at::Tensor, std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x21 (0x7fc8780e82e1 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #13: c10d::ProcessGroupNCCL::allreduce(std::vector<at::Tensor, std::allocator<at::Tensor> >&, c10d::AllreduceOptions const&) + 0x421 (0x7fc8780ea121 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #14: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x8e4 (0x7fc8780f9994 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #15: <unknown function> + 0x4935c6f (0x7fc8c4d37c6f in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0x494575c (0x7fc8c4d4775c in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x4952b12 (0x7fc8c4d54b12 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #18: <unknown function> + 0x49535b9 (0x7fc8c4d555b9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xb868a2 (0x7fc8cb51c8a2 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #20: <unknown function> + 0x39c407 (0x7fc8cad32407 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #21: <unknown function> + 0x15fe0e (0x561d89608e0e in /usr/bin/python)
frame #22: _PyObject_MakeTpCall + 0x25b (0x561d895ff5eb in /usr/bin/python)
frame #23: <unknown function> + 0x16e7bb (0x561d896177bb in /usr/bin/python)
frame #24: _PyEval_EvalFrameDefault + 0x1981 (0x561d895f30d1 in /usr/bin/python)
frame #25: _PyFunction_Vectorcall + 0x7c (0x561d8960970c in /usr/bin/python)
frame #26: _PyEval_EvalFrameDefault + 0x2b71 (0x561d895f42c1 in /usr/bin/python)
frame #27: _PyFunction_Vectorcall + 0x7c (0x561d8960970c in /usr/bin/python)
frame #28: _PyEval_EvalFrameDefault + 0x6152 (0x561d895f78a2 in /usr/bin/python)
frame #29: _PyFunction_Vectorcall + 0x7c (0x561d8960970c in /usr/bin/python)
frame #30: _PyEval_EvalFrameDefault + 0x6bd (0x561d895f1e0d in /usr/bin/python)
frame #31: _PyFunction_Vectorcall + 0x7c (0x561d8960970c in /usr/bin/python)
frame #32: _PyEval_EvalFrameDefault + 0x1981 (0x561d895f30d1 in /usr/bin/python)
frame #33: _PyFunction_Vectorcall + 0x7c (0x561d8960970c in /usr/bin/python)
frame #34: _PyEval_EvalFrameDefault + 0x1981 (0x561d895f30d1 in /usr/bin/python)
frame #35: <unknown function> + 0x239e56 (0x561d896e2e56 in /usr/bin/python)
frame #36: PyEval_EvalCode + 0x86 (0x561d896e2cf6 in /usr/bin/python)
frame #37: <unknown function> + 0x2647d8 (0x561d8970d7d8 in /usr/bin/python)
frame #38: <unknown function> + 0x25e0bb (0x561d897070bb in /usr/bin/python)
frame #39: <unknown function> + 0x264525 (0x561d8970d525 in /usr/bin/python)
frame #40: _PyRun_SimpleFileObject + 0x1a8 (0x561d8970ca08 in /usr/bin/python)
frame #41: _PyRun_AnyFileObject + 0x43 (0x561d8970c653 in /usr/bin/python)
frame #42: Py_RunMain + 0x2be (0x561d896ff41e in /usr/bin/python)
frame #43: Py_BytesMain + 0x2d (0x561d896d5cad in /usr/bin/python)
frame #44: <unknown function> + 0x29d90 (0x7fc913804d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #45: __libc_start_main + 0x80 (0x7fc913804e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #46: _start + 0x25 (0x561d896d5ba5 in /usr/bin/python)
. This may indicate a possible application crash on rank 0 or a network set up issue.
[2024-02-09 12:42:49,759] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239653 closing signal SIGTERM
[2024-02-09 12:42:49,760] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239654 closing signal SIGTERM
[2024-02-09 12:42:49,761] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239655 closing signal SIGTERM
[2024-02-09 12:42:49,761] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239656 closing signal SIGTERM
[2024-02-09 12:42:49,761] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239657 closing signal SIGTERM
[2024-02-09 12:42:49,762] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239658 closing signal SIGTERM
[2024-02-09 12:42:49,763] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239660 closing signal SIGTERM
[2024-02-09 12:42:50,432] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 6 (pid: 239659) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_12:42:49
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 239659)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=4, pp=1, mbs=8
LOCAL_IP = 10.64.24.51
DP=4, MP=4, PP=1
[2024-02-09 12:45:03,079] torch.distributed.run: [WARNING] 
[2024-02-09 12:45:03,079] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 12:45:03,079] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 12:45:03,079] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 4, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 8
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 4
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 16
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 431 dummy tokens (new size: 50688)
> initializing torch distributed ...
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: [enforce fail at /opt/pytorch/pytorch/third_party/gloo/gloo/transport/tcp/address.cc:45] sizeof(impl_) == bytes.size(). 136 vs 45
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: [enforce fail at /opt/pytorch/pytorch/third_party/gloo/gloo/transport/tcp/address.cc:45] sizeof(impl_) == bytes.size(). 136 vs 45
[E ProcessGroupGloo.cpp:138] Gloo connectFullMesh failed with [/opt/pytorch/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:144] no error
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Gloo connectFullMesh failed with [/opt/pytorch/pytorch/third_party/gloo/gloo/transport/tcp/pair.cc:144] no error
[2024-02-09 12:46:08,854] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239897 closing signal SIGTERM
[2024-02-09 12:46:08,855] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239899 closing signal SIGTERM
[2024-02-09 12:46:08,855] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239901 closing signal SIGTERM
[2024-02-09 12:46:08,856] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239902 closing signal SIGTERM
[2024-02-09 12:46:08,856] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 239903 closing signal SIGTERM
[2024-02-09 12:46:09,448] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 239896) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_12:46:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 239898)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_12:46:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 239900)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_12:46:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 239896)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=4, pp=1, mbs=4
LOCAL_IP = 10.64.24.51
DP=4, MP=4, PP=1
[2024-02-09 12:48:42,100] torch.distributed.run: [WARNING] 
[2024-02-09 12:48:42,100] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 12:48:42,100] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 12:48:42,100] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 4, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 4
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 32
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 431 dummy tokens (new size: 50688)
> initializing torch distributed ...
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
[2024-02-09 13:19:08,902] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 240434) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_13:19:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 240435)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_13:19:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 240436)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_13:19:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 240437)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_13:19:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 240438)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_13:19:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 240439)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_13:19:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 240440)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_13:19:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 240441)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_13:19:08
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 240434)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=4, pp=1, mbs=2
LOCAL_IP = 10.64.24.51
DP=4, MP=4, PP=1
[2024-02-09 13:22:31,680] torch.distributed.run: [WARNING] 
[2024-02-09 13:22:31,680] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 13:22:31,680] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 13:22:31,680] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 4, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 2
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 4
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 64
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 431 dummy tokens (new size: 50688)
> initializing torch distributed ...
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
[2024-02-09 13:53:17,954] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 240670) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_13:53:17
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 240671)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_13:53:17
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 240672)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_13:53:17
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 240673)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_13:53:17
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 240674)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_13:53:17
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 240675)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_13:53:17
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 240676)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_13:53:17
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 240677)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_13:53:17
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 240670)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=4, pp=1, mbs=1
LOCAL_IP = 10.64.24.51
DP=4, MP=4, PP=1
[2024-02-09 13:56:40,692] torch.distributed.run: [WARNING] 
[2024-02-09 13:56:40,692] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 13:56:40,692] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 13:56:40,692] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 4, pipeline-model-parallel size: 1 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 1
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 4
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 128
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 431 dummy tokens (new size: 50688)
> initializing torch distributed ...
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
RuntimeError: Socket Timeout
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 91, in pretrain
    initialize_megatron(extra_args_provider=extra_args_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 76, in initialize_megatron
    finish_mpu_init()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 56, in finish_mpu_init
    _initialize_distributed()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 185, in _initialize_distributed
    mpu.initialize_model_parallel(args.tensor_model_parallel_size,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/core/parallel_state.py", line 166, in initialize_model_parallel
    group_gloo = torch.distributed.new_group(ranks, backend="gloo")
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 74, in wrapper
    func_return = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3870, in new_group
    return _new_group_with_tag(ranks, timeout, backend, pg_options, None, use_local_synchronization=use_local_synchronization)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 3933, in _new_group_with_tag
    pg, pg_store = _new_process_group_helper(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 1269, in _new_process_group_helper
    backend_class = ProcessGroupGloo(backend_prefix_store, group_rank, group_size, timeout=timeout)
RuntimeError: Socket Timeout
[2024-02-09 14:28:39,980] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 240906) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_14:28:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 240907)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_14:28:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 240908)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_14:28:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 240909)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_14:28:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 240910)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_14:28:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 240911)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_14:28:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 240912)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_14:28:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 240913)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_14:28:39
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 240906)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=1, pp=4, mbs=32
LOCAL_IP = 10.64.24.51
DP=4, MP=1, PP=4
[2024-02-09 14:32:02,737] torch.distributed.run: [WARNING] 
[2024-02-09 14:32:02,737] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 14:32:02,737] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 14:32:02,737] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 4 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 32
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 4
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 4
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 4
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 4
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.125 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 8.409 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 1068507 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 1068511 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 1068506 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 1068509 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 1068508 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

        pretrain(train_dataset_provider,_warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function

  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 1068504 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 1068505 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "<string>", line 3, in bias_gelu

def mul(a : float, b : Tensor) -> Tensor:
  return b * a
         ~~~~~ <--- HERE
def add(a : float, b : Tensor) -> Tensor:
  return b + a
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 17.48 GiB is free. Process 1068510 has 61.62 GiB memory in use. Of the allocated memory 60.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[2024-02-09 14:33:30,385] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 241142) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_14:33:30
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 241143)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_14:33:30
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 241144)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_14:33:30
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 241145)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_14:33:30
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 241146)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_14:33:30
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 241147)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_14:33:30
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 241148)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_14:33:30
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 241149)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_14:33:30
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 241142)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=1, pp=4, mbs=16
LOCAL_IP = 10.64.24.51
DP=4, MP=1, PP=4
[2024-02-09 14:36:53,151] torch.distributed.run: [WARNING] 
[2024-02-09 14:36:53,151] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 14:36:53,151] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 14:36:53,151] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 4 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 16
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 4
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 4
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 8
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 4
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.087 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 8.259 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1075600 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1075599 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1075593 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1075597 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1075598 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
    output = bias_gelu(bias, input)
RuntimeErrorRuntimeError: : The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1075596 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1075594 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1075595 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[2024-02-09 14:40:14,248] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 241597) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_14:40:14
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 241598)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_14:40:14
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 241599)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_14:40:14
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 241600)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_14:40:14
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 241601)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_14:40:14
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 241602)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_14:40:14
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 241603)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_14:40:14
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 241604)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_14:40:14
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 241597)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=1, pp=4, mbs=8
LOCAL_IP = 10.64.24.51
DP=4, MP=1, PP=4
[2024-02-09 14:43:37,022] torch.distributed.run: [WARNING] 
[2024-02-09 14:43:37,022] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 14:43:37,022] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 14:43:37,022] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 4 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 8
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 4
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 4
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 16
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 4
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.098 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.553 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1082255 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1082257 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1082252 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1082254 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1082258 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1082256 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1082253 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1082259 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


[2024-02-09 14:46:47,984] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 242052) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_14:46:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 242053)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_14:46:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 242054)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_14:46:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 242055)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_14:46:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 242056)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_14:46:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 242057)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_14:46:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 242058)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_14:46:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 242059)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_14:46:47
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 242052)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=1, pp=4, mbs=4
LOCAL_IP = 10.64.24.51
DP=4, MP=1, PP=4
[2024-02-09 14:50:10,767] torch.distributed.run: [WARNING] 
[2024-02-09 14:50:10,767] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 14:50:10,767] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 14:50:10,767] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 4 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 4
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 4
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 32
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 4
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.096 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.663 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 13.330
[after megatron is initialized] datetime: 2024-02-09 14:53:18 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 3146393600
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
[E ProcessGroupNCCL.cpp:467] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600788 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600840 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600889 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600922 milliseconds before timing out.
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600788 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600788 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600889 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600889 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600840 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600840 milliseconds before timing out.
Loading exists cache end, time cost:  4.694 s
Cutting or padding data to max_seq_len + 1 = 16385 begin ...
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600922 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600922 milliseconds before timing out.
[2024-02-09 15:03:27,326] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242507 closing signal SIGTERM
[2024-02-09 15:03:27,326] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242508 closing signal SIGTERM
[2024-02-09 15:03:27,327] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242509 closing signal SIGTERM
[2024-02-09 15:03:27,327] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242510 closing signal SIGTERM
[2024-02-09 15:03:27,328] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242511 closing signal SIGTERM
[2024-02-09 15:03:27,328] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242512 closing signal SIGTERM
[2024-02-09 15:03:32,576] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 6 (pid: 242513) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
pretrain_gpt.py FAILED
-------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_15:03:27
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : -6 (pid: 242514)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 242514
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_15:03:27
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : -6 (pid: 242513)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 242513
=======================================================
13b, 16k, gbs=512: dp=4, tp=1, pp=4, mbs=2
LOCAL_IP = 10.64.24.51
DP=4, MP=1, PP=4
[2024-02-09 15:05:55,215] torch.distributed.run: [WARNING] 
[2024-02-09 15:05:55,215] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 15:05:55,215] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 15:05:55,215] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 4 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 2
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 4
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 4
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 64
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 4
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.107 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.538 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])

SYM206-GPU-A0205-P2-Node51:242970:243310 [0] ib_plugin.c:1007 NCCL WARN NET/IB : Got completion from peer 10.64.24.52<43148> with error 12, opcode 129, len 0, vendor err 129

SYM206-GPU-A0205-P2-Node51:242970:243310 [0] ib_plugin.c:1007 NCCL WARN NET/IB : Got completion from peer 10.64.24.52<43148> with error 5, opcode 129, len 0, vendor err 244
time to initialize megatron (seconds): 1707462633.424
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 0] NCCL watchdog thread terminated with exception: NCCL error: remote process exited or there was a network error, NCCL version 2.19.3
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
NET/IB : Got completion from peer 10.64.24.52<43148> with error 5, opcode 129, len 0, vendor err 244
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: NCCL error: remote process exited or there was a network error, NCCL version 2.19.3
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
NET/IB : Got completion from peer 10.64.24.52<43148> with error 5, opcode 129, len 0, vendor err 244
[2024-02-09 15:10:42,805] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242971 closing signal SIGTERM
[2024-02-09 15:10:42,805] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242972 closing signal SIGTERM
[2024-02-09 15:10:42,806] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242973 closing signal SIGTERM
[2024-02-09 15:10:42,807] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242974 closing signal SIGTERM
[2024-02-09 15:10:42,807] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242975 closing signal SIGTERM
[2024-02-09 15:10:42,808] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242976 closing signal SIGTERM
[2024-02-09 15:10:42,808] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 242977 closing signal SIGTERM
[2024-02-09 15:10:43,686] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 0 (pid: 242970) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
pretrain_gpt.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_15:10:42
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : -6 (pid: 242970)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 242970
=======================================================
13b, 16k, gbs=512: dp=4, tp=1, pp=4, mbs=1
LOCAL_IP = 10.64.24.51
DP=4, MP=1, PP=4
[2024-02-09 15:12:56,292] torch.distributed.run: [WARNING] 
[2024-02-09 15:12:56,292] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 15:12:56,292] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 15:12:56,292] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 1, pipeline-model-parallel size: 4 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 1
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 4
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 4
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 128
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 4
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.126 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 8.191 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 11.929
[after megatron is initialized] datetime: 2024-02-09 15:14:10 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 3146393600
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
[E ProcessGroupNCCL.cpp:467] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600307 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600317 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600324 milliseconds before timing out.
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
Loading exists cache from /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_cache.pkl begin ...
[E ProcessGroupNCCL.cpp:467] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600887 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600324 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:852] [Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600887 milliseconds before timing out.
terminate called after throwing an instance of 'terminate called after throwing an instance of 'std::runtime_errorstd::runtime_error'
'
  what():    what():  [Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600324 milliseconds before timing out.[Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600887 milliseconds before timing out.

[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600317 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600317 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600307 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600307 milliseconds before timing out.
[2024-02-09 15:24:18,443] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 243425 closing signal SIGTERM
[2024-02-09 15:24:18,444] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 243426 closing signal SIGTERM
[2024-02-09 15:24:18,444] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 243427 closing signal SIGTERM
[2024-02-09 15:24:18,445] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 243428 closing signal SIGTERM
[2024-02-09 15:24:18,445] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 243430 closing signal SIGTERM
[2024-02-09 15:24:18,446] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 243431 closing signal SIGTERM
[2024-02-09 15:24:18,446] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 243432 closing signal SIGTERM
[2024-02-09 15:24:23,457] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 4 (pid: 243429) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
pretrain_gpt.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_15:24:18
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : -6 (pid: 243429)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 243429
=======================================================
13b, 16k, gbs=512: dp=4, tp=2, pp=2, mbs=32
LOCAL_IP = 10.64.24.51
DP=4, MP=2, PP=2
[2024-02-09 15:26:36,112] torch.distributed.run: [WARNING] 
[2024-02-09 15:26:36,112] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 15:26:36,112] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 15:26:36,112] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 2, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 32
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 4
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.111 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.507 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1123896 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1123892 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1123898 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1123895 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1123899 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1123893 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1123894 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in bias_gelu
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 7.48 GiB is free. Process 1123897 has 71.62 GiB memory in use. Of the allocated memory 70.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[2024-02-09 15:28:44,376] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 243888) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_15:28:44
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 243889)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_15:28:44
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 243890)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_15:28:44
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 243891)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_15:28:44
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 243892)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_15:28:44
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 243893)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_15:28:44
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 243894)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_15:28:44
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 243895)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_15:28:44
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 243888)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=2, pp=2, mbs=16
LOCAL_IP = 10.64.24.51
DP=4, MP=2, PP=2
[2024-02-09 15:32:07,131] torch.distributed.run: [WARNING] 
[2024-02-09 15:32:07,131] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 15:32:07,131] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 15:32:07,131] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 2, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 16
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 8
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.102 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.726 seconds
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 6 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1130799 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 2 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1130795 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 5 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1130798 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 3 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1130796 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 4 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1130797 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 7 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1130800 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
Traceback (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/pretrain_gpt.py", line 203, in <module>
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    pretrain(train_dataset_provider,
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py", line 94, in pretrain
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    set_jit_fusion_options()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 253, in set_jit_fusion_options
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    _warmup_jit_function()
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py", line 277, in _warmup_jit_function
    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 0 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1130793 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


    output = bias_gelu(bias, input)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript (most recent call last):
  File "/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/model/fused_bias_gelu.py", line 17, in <forward op>
def bias_gelu(bias, y):
    x = bias + y
    return  x * 0.5 * (1.0 + torch.tanh(0.79788456 * x * (1 + 0.044715 * x * x)))
                             ~~~~~~~~~~ <--- HERE
RuntimeError: CUDA out of memory. Tried to allocate 5.00 GiB. GPU 1 has a total capacty of 79.11 GiB of which 2.48 GiB is free. Process 1130794 has 76.62 GiB memory in use. Of the allocated memory 75.00 GiB is allocated by PyTorch, and 1.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


[2024-02-09 15:35:28,172] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 244351) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
pretrain_gpt.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_15:35:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 244352)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2024-02-09_15:35:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 244353)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2024-02-09_15:35:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 244354)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2024-02-09_15:35:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 244355)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2024-02-09_15:35:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 244356)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2024-02-09_15:35:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 244357)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2024-02-09_15:35:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 244358)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_15:35:28
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 244351)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
13b, 16k, gbs=512: dp=4, tp=2, pp=2, mbs=8
LOCAL_IP = 10.64.24.51
DP=4, MP=2, PP=2
[2024-02-09 15:38:50,915] torch.distributed.run: [WARNING] 
[2024-02-09 15:38:50,915] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 15:38:50,915] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 15:38:50,915] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 2, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 8
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 16
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.099 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.880 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 12.038
[after megatron is initialized] datetime: 2024-02-09 15:41:58 
building GPT model ...
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
[E ProcessGroupNCCL.cpp:467] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1, OpType=ALLREDUCE, NumelIn=129105920, NumelOut=129105920, Timeout(ms)=1800000) ran for 1800584 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1, OpType=ALLREDUCE, NumelIn=129105920, NumelOut=129105920, Timeout(ms)=1800000) ran for 1800619 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1, OpType=ALLREDUCE, NumelIn=129105920, NumelOut=129105920, Timeout(ms)=1800000) ran for 1800649 milliseconds before timing out.
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/optimizer/distrib_optimizer.py:412: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  storage = grad_buffer.data.storage()._untyped()
[E ProcessGroupNCCL.cpp:467] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600173 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1, OpType=ALLREDUCE, NumelIn=129105920, NumelOut=129105920, Timeout(ms)=1800000) ran for 1800649 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1, OpType=ALLREDUCE, NumelIn=129105920, NumelOut=129105920, Timeout(ms)=1800000) ran for 1800649 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:467] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=6, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600283 milliseconds before timing out.
[E ProcessGroupNCCL.cpp:481] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[E ProcessGroupNCCL.cpp:487] To avoid data inconsistency, we are taking the entire process down.
[E ProcessGroupNCCL.cpp:852] [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1, OpType=ALLREDUCE, NumelIn=129105920, NumelOut=129105920, Timeout(ms)=1800000) ran for 1800619 milliseconds before timing out.
terminate called after throwing an instance of 'std::runtime_error'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1, OpType=ALLREDUCE, NumelIn=129105920, NumelOut=129105920, Timeout(ms)=1800000) ran for 1800619 milliseconds before timing out.
[2024-02-09 16:22:09,360] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 244814 closing signal SIGTERM
[2024-02-09 16:22:09,360] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 244815 closing signal SIGTERM
[2024-02-09 16:22:09,361] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 244816 closing signal SIGTERM
[2024-02-09 16:22:09,362] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 244817 closing signal SIGTERM
[2024-02-09 16:22:09,363] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 244818 closing signal SIGTERM
[2024-02-09 16:22:09,363] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 244819 closing signal SIGTERM
[2024-02-09 16:22:11,831] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -6) local_rank: 6 (pid: 244820) of binary: /usr/bin/python
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
pretrain_gpt.py FAILED
-------------------------------------------------------
Failures:
[1]:
  time      : 2024-02-09_16:22:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 7 (local_rank: 7)
  exitcode  : -6 (pid: 244821)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 244821
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-02-09_16:22:09
  host      : SYM206-GPU-A0205-P2-Node51
  rank      : 6 (local_rank: 6)
  exitcode  : -6 (pid: 244820)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 244820
=======================================================
13b, 16k, gbs=512: dp=4, tp=2, pp=2, mbs=4
LOCAL_IP = 10.64.24.51
DP=4, MP=2, PP=2
[2024-02-09 16:24:34,475] torch.distributed.run: [WARNING] 
[2024-02-09 16:24:34,475] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 16:24:34,475] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 16:24:34,475] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 2, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 32
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.105 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
>>> done with compiling and loading fused kernels. Compilation time: 7.614 seconds
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/initialize.py:277: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/training.py:100: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  start_time_tensor = torch.cuda.DoubleTensor([_TRAIN_START_TIME])
time to initialize megatron (seconds): 12.177
[after megatron is initialized] datetime: 2024-02-09 16:25:09 
building GPT model ...
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
NCCL version 2.19.3+cuda12.2
[2024-02-09 17:24:32,337] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGTERM death signal, shutting down workers
[2024-02-09 17:24:32,338] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 245606 closing signal SIGTERM
[2024-02-09 17:24:32,339] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 245607 closing signal SIGTERM
[2024-02-09 17:24:32,339] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 245608 closing signal SIGTERM
[2024-02-09 17:24:32,339] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 245609 closing signal SIGTERM
[2024-02-09 17:24:32,339] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 245610 closing signal SIGTERM
[2024-02-09 17:24:32,339] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 245611 closing signal SIGTERM
[2024-02-09 17:24:32,339] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 245612 closing signal SIGTERM
[2024-02-09 17:24:32,339] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 245613 closing signal SIGTERM
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 33, in <module>
    sys.exit(load_entry_point('torch==2.1.0a0+32f93b1', 'console_scripts', 'torchrun')())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    result = agent.run()
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py", line 736, in run
    result = self._invoke_run(role)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py", line 877, in _invoke_run
    time.sleep(monitor_interval)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 245531 got signal: 15
13b, 16k, gbs=512: dp=4, tp=2, pp=2, mbs=2
LOCAL_IP = 10.64.24.51
DP=4, MP=2, PP=2
[2024-02-09 17:25:04,474] torch.distributed.run: [WARNING] 
[2024-02-09 17:25:04,474] torch.distributed.run: [WARNING] *****************************************
[2024-02-09 17:25:04,474] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-02-09 17:25:04,474] torch.distributed.run: [WARNING] *****************************************
using world size: 16, data-parallel-size: 4, tensor-model-parallel size: 2, pipeline-model-parallel size: 2 
accumulate and all-reduce gradients in fp32 for bfloat16 data type.
using torch.bfloat16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. True
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  async_tensor_model_parallel_allreduce ........... False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ True
  bias_dropout_fusion ............................. False
  bias_gelu_fusion ................................ False
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_cache_path ................................. None
  data_impl ....................................... mmap
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 4
  data_path ....................................... ['/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0_content_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  embedding_weights_in_fp32 ....................... False
  empty_unused_memory_level ....................... 0
  encoder_num_layers .............................. 40
  encoder_seq_length .............................. 16384
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  ffn_hidden_size ................................. 20480
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_e4m3 ........................................ False
  fp8_hybrid ...................................... False
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 512
  gradient_accumulation_fusion .................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 5120
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  iter_per_epoch .................................. 1250
  json_file ....................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/web/refinedweb0.json
  json_key ........................................ content
  kv_channels ..................................... 128
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 10
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... False
  max_position_embeddings ......................... 16384
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/merges.txt
  micro_batch_size ................................ 2
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 40
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 40
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_p2p_comm ................................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.bfloat16
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 2
  pipeline_model_parallel_split_rank .............. None
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ 1
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_return_doc_ids ............................ False
  retro_workdir ................................... None
  rotary_percent .................................. 1.0
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 16384
  sequence_packing ................................ True
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 2
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  timing_log_level ................................ 2
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  train_data_path ................................. None
  train_iters ..................................... 100
  train_samples ................................... None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 2
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_contiguous_buffers_in_local_ddp ............. True
  use_cpu_initialization .......................... None
  use_distributed_optimizer ....................... True
  use_flash_attn .................................. True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  valid_data_path ................................. None
  variable_seq_lengths ............................ True
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/data/vocab.json
  vocab_size ...................................... None
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 16
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 64
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 175 dummy tokens (new size: 50432)
> initializing torch distributed ...
> initialized tensor model parallel with size 2
> initialized pipeline model parallel with size 2
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
make: Nothing to be done for 'default'.
make: Leaving directory '/data/nolan/develop/bak/ht/hot_switch/gh/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 0.100 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
NCCL version 2.19.3+cuda12.2
